======= Create directory to store trained models: ./results/ct_dma-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/
2025-03-26 00:04:39,532 - models - number of parameters: 5.742055e+07
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 1 iter 2: loss 9.91155. lr 4.415845e-04:  19% 3/16 [01:58<08:33, 39.48s/it] 
Traceback (most recent call last):
  File "/content/EnhnTrAISformer/main_training.py", line 106, in <module>
    main()
  File "/content/EnhnTrAISformer/main_training.py", line 40, in main
    trainer.train()
  File "/content/EnhnTrAISformer/trainers.py", line 249, in train
    run_epoch('Training', epoch=epoch)
  File "/content/EnhnTrAISformer/trainers.py", line 182, in run_epoch
    loss.backward()
  File "/usr/local/lib/python3.11/dist-packages/torch/_tensor.py", line 626, in backward
    torch.autograd.backward(
  File "/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py", line 823, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
