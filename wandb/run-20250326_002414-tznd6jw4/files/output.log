======= Directory to store trained models: ./results/ct_dma-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/
2025-03-26 00:24:16,318 - models - number of parameters: 5.742055e+07
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 1 iter 15: loss 4.58432. lr 5.804990e-04: 100% 16/16 [00:06<00:00,  2.50it/s]
2025-03-26 00:24:24,078 - root - Training, epoch 1, loss 8.08858, lr 5.804990e-04.
2025-03-26 00:24:24,447 - root - Valid, epoch 1, loss 5.86858.
2025-03-26 00:24:24,448 - root - Best epoch: 001, saving model to ./results/ct_dma-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/model.pt
2025-03-26 00:24:27,520 - numexpr.utils - NumExpr defaulting to 2 threads.
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 2 iter 15: loss 5.78200. lr 4.543956e-04: 100% 16/16 [00:05<00:00,  2.68it/s]
2025-03-26 00:24:33,832 - root - Training, epoch 2, loss 4.86527, lr 4.543956e-04.
2025-03-26 00:24:34,468 - root - Valid, epoch 2, loss 4.69431.
2025-03-26 00:24:34,470 - root - Best epoch: 002, saving model to ./results/ct_dma-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/model.pt
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 3 iter 15: loss 4.54293. lr 2.619886e-04: 100% 16/16 [00:05<00:00,  2.70it/s]
2025-03-26 00:24:45,009 - root - Training, epoch 3, loss 3.97016, lr 2.619886e-04.
2025-03-26 00:24:45,418 - root - Valid, epoch 3, loss 3.79082.
2025-03-26 00:24:45,419 - root - Best epoch: 003, saving model to ./results/ct_dma-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/model.pt
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 4 iter 15: loss 2.14308. lr 8.590517e-05: 100% 16/16 [00:05<00:00,  2.69it/s]
2025-03-26 00:24:53,828 - root - Training, epoch 4, loss 3.23290, lr 8.590517e-05.
2025-03-26 00:24:54,249 - root - Valid, epoch 4, loss 3.13089.
2025-03-26 00:24:54,251 - root - Best epoch: 004, saving model to ./results/ct_dma-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/model.pt
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 5 iter 15: loss 4.07133. lr 6.000000e-05: 100% 16/16 [00:06<00:00,  2.65it/s]
2025-03-26 00:25:02,660 - root - Training, epoch 5, loss 2.78021, lr 6.000000e-05.
2025-03-26 00:25:03,078 - root - Valid, epoch 5, loss 2.83403.
2025-03-26 00:25:03,080 - root - Best epoch: 005, saving model to ./results/ct_dma-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/model.pt
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 6 iter 15: loss 2.15095. lr 6.000000e-05: 100% 16/16 [00:06<00:00,  2.66it/s]
2025-03-26 00:25:11,489 - root - Training, epoch 6, loss 2.45078, lr 6.000000e-05.
2025-03-26 00:25:11,892 - root - Valid, epoch 6, loss 2.54722.
2025-03-26 00:25:11,894 - root - Best epoch: 006, saving model to ./results/ct_dma-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/model.pt
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 7 iter 15: loss 3.30916. lr 1.988363e-04: 100% 16/16 [00:06<00:00,  2.59it/s]
2025-03-26 00:25:21,186 - root - Training, epoch 7, loss 2.22823, lr 1.988363e-04.
2025-03-26 00:25:21,600 - root - Valid, epoch 7, loss 2.44236.
2025-03-26 00:25:21,601 - root - Best epoch: 007, saving model to ./results/ct_dma-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/model.pt
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 8 iter 15: loss 1.45694. lr 3.954212e-04: 100% 16/16 [00:06<00:00,  2.54it/s]
2025-03-26 00:25:30,372 - root - Training, epoch 8, loss 1.93077, lr 3.954212e-04.
2025-03-26 00:25:30,778 - root - Valid, epoch 8, loss 2.15041.
2025-03-26 00:25:30,779 - root - Best epoch: 008, saving model to ./results/ct_dma-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/model.pt
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 9 iter 15: loss 2.17281. lr 5.510284e-04: 100% 16/16 [00:06<00:00,  2.50it/s]
2025-03-26 00:25:40,172 - root - Training, epoch 9, loss 1.85443, lr 5.510284e-04.
2025-03-26 00:25:40,701 - root - Valid, epoch 9, loss 2.12303.
2025-03-26 00:25:40,703 - root - Best epoch: 009, saving model to ./results/ct_dma-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/model.pt
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 10 iter 15: loss 2.97399. lr 5.988340e-04: 100% 16/16 [00:06<00:00,  2.50it/s]
2025-03-26 00:25:50,376 - root - Training, epoch 10, loss 1.80477, lr 5.988340e-04.
2025-03-26 00:25:50,851 - root - Valid, epoch 10, loss 2.17474.
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 11 iter 15: loss -1.29087. lr 5.183084e-04: 100% 16/16 [00:06<00:00,  2.43it/s]
2025-03-26 00:25:59,721 - root - Training, epoch 11, loss 1.70298, lr 5.183084e-04.
2025-03-26 00:26:00,149 - root - Valid, epoch 11, loss 2.00933.
2025-03-26 00:26:00,150 - root - Best epoch: 011, saving model to ./results/ct_dma-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/model.pt
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 12 iter 15: loss 1.05487. lr 3.440324e-04: 100% 16/16 [00:06<00:00,  2.48it/s]
2025-03-26 00:26:09,300 - root - Training, epoch 12, loss 1.59669, lr 3.440324e-04.
2025-03-26 00:26:09,725 - root - Valid, epoch 12, loss 2.07160.
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 13 iter 15: loss 1.76367. lr 1.508471e-04: 100% 16/16 [00:06<00:00,  2.45it/s]
2025-03-26 00:26:18,134 - root - Training, epoch 13, loss 1.54318, lr 1.508471e-04.
2025-03-26 00:26:18,651 - root - Valid, epoch 13, loss 1.76354.
2025-03-26 00:26:18,652 - root - Best epoch: 013, saving model to ./results/ct_dma-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/model.pt
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
epoch 14 iter 13: loss 1.65280. lr 1.072672e-04:  88% 14/16 [00:06<00:00,  2.32it/s]
Traceback (most recent call last):
  File "/content/EnhnTrAISformer/main_training.py", line 106, in <module>
    main()
  File "/content/EnhnTrAISformer/main_training.py", line 40, in main
    trainer.train()
  File "/content/EnhnTrAISformer/utils_training.py", line 180, in train
    run_epoch('Training', epoch=epoch)
  File "/content/EnhnTrAISformer/utils_training.py", line 101, in run_epoch
    losses.append(loss.item())
                  ^^^^^^^^^^^
KeyboardInterrupt
